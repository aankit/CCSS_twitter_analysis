{
 "metadata": {
  "name": "",
  "signature": "sha256:46bad144c646ba573126a30b4fed2c0d7cec754ffb3c8785439070a6a748feec"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from string import punctuation, ascii_lowercase\n",
      "from itertools import permutations, combinations\n",
      "from patterns import *\n",
      "from nltk.tokenize import wordpunct_tokenize\n",
      "nltk.data.path.append('./tweetEasy/nltk_data/') #this may need to change depending on when\n",
      "from nltk.corpus import stopwords\n",
      "from collections import Counter\n",
      "from tweetsql.model import Tweet, Hashtag, User\n",
      "from tweetsql.database import db_session\n",
      "import pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hashtag_input = open('user_hashtag.p', 'rb')\n",
      "db_hashtags = pickle.load(hashtag_input)\n",
      "tweet_input = open('user_tweet.p', 'rb')\n",
      "tweets = pickle.load(tweet_input)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#load global lists of stopwords here\n",
      "adhoc_stop = ['RT', 'via', '...', 'http', '://', 'co', 're', 'de', 'amp', 'gt', 'common', 'core', 'ccss', 'commoncore', 'standards']\n",
      "punctuation = list(punctuation) + [''.join(t) for t in list(permutations(punctuation, 2))] + [''.join(t) for t in list(permutations(punctuation, 3))]\n",
      "global_stop = stopwords.words('english') + [ts.lower() for ts in adhoc_stop] + list(ascii_lowercase)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "tweetdf = pd.DataFrame(tweets, columns=['screen_name', 'uid', 'tweet'])\n",
      "hashtagdf = pd.DataFrame(db_hashtags, columns=['screen_name', 'hashtag'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hashtagdf.head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>screen_name</th>\n",
        "      <th>hashtag</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>   JennWillTeach</td>\n",
        "      <td>     CommonCore</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>       laniec570</td>\n",
        "      <td> stopcommoncore</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>      RAlanEagle</td>\n",
        "      <td>        foxnews</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>       InnEduSol</td>\n",
        "      <td>     CommonCore</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>         NTampio</td>\n",
        "      <td>          PARCC</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td> Discoveringme40</td>\n",
        "      <td>     CommonCore</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td> Discoveringme40</td>\n",
        "      <td>          PJNET</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td> Discoveringme40</td>\n",
        "      <td>           WAAR</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td>   noprezzie2012</td>\n",
        "      <td>     CommonCore</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td>   noprezzie2012</td>\n",
        "      <td>        Arizona</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "       screen_name         hashtag\n",
        "0    JennWillTeach      CommonCore\n",
        "1        laniec570  stopcommoncore\n",
        "2       RAlanEagle         foxnews\n",
        "3        InnEduSol      CommonCore\n",
        "4          NTampio           PARCC\n",
        "5  Discoveringme40      CommonCore\n",
        "6  Discoveringme40           PJNET\n",
        "7  Discoveringme40            WAAR\n",
        "8    noprezzie2012      CommonCore\n",
        "9    noprezzie2012         Arizona"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list(tweetdf[tweetdf.screen_name=='MichelleMelkin'].tweet)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 99,
       "text": [
        "[]"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#filter for top tweeter's tweets\n",
      "sn_counter = Counter()\n",
      "sn_counter.update([sn for sn, u, t in tweets])\n",
      "top_tweeter_tweets = [(sn,u,t) for sn, u, t in tweets if sn_counter[sn]>2] #number of tweets of screen_name is greater than 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#percentage of tweets from top tweeters - is this too low? should I have let them all in?\n",
      "x = float(len(top_tweeter_tweets))/len(tweets)\n",
      "print x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.475350994995\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def notShout(tokens):\n",
      "    shout_tolerance = .6\n",
      "    length = len(tokens)\n",
      "    if length >0:\n",
      "        shout_count = 0.0\n",
      "        for word in tokens:\n",
      "            if word.isupper():\n",
      "                shout_count += 1\n",
      "        if shout_count/length<shout_tolerance:\n",
      "            return True\n",
      "        else:\n",
      "            return False\n",
      "    else:\n",
      "        return False\n",
      "\n",
      "    # functions that help us construct the graph\n",
      "def graph_add_node(n, g, params):\n",
      "    try:\n",
      "        if g.has_node(n):\n",
      "            g.node[n]['weight']+=1\n",
      "        else:\n",
      "            g.add_node(n)\n",
      "            g.node[n]['weight'] = 1\n",
      "            for k,v in params.items():\n",
      "                g.node[n][k]=v\n",
      "    except:\n",
      "        return\n",
      "            \n",
      "def graph_add_edge(n1, n2, g):\n",
      "    if g.has_edge(n1, n2):\n",
      "        g[n1][n2]['weight']+=1\n",
      "    else:\n",
      "        g.add_edge(n1,n2)\n",
      "        g[n1][n2]['weight']=1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_count = Counter()\n",
      "\n",
      "hashtag_set = set([ht.lower() for u, ht in db_hashtags])\n",
      "hashtag_count = Counter([ht.lower() for u, ht in db_hashtags])\n",
      "hashtagco = {} #hashtag co-occurence dictionary\n",
      "\n",
      "cap_words_count = Counter()\n",
      "acronyms_count = Counter()\n",
      "mentions_count = Counter()\n",
      "retweets_count = Counter()\n",
      "url_set = set()\n",
      "\n",
      "import networkx as nx\n",
      "from networkx.algorithms import bipartite\n",
      "user_words = nx.Graph()\n",
      "wordco = nx.Graph()\n",
      "hashtagco = nx.Graph()\n",
      "user_hashtag = nx.Graph()\n",
      "user_retweets = nx.Graph()\n",
      "user_mentions = nx.Graph()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(top_tweeter_tweets)\n",
      "print len(tweets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "19468\n",
        "40955\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "shout_count = 0\n",
      "tweets_retweeted = 0\n",
      "user_word_dict = {}\n",
      "for screen_name, user_id, tweet in tweets:\n",
      "    check = tweet\n",
      "    tweet = tweet.strip()\n",
      "    tweet = tweet.encode('ascii', 'ignore')\n",
      "    hashtags, tweet = regex_clean(re_hashtag, tweet)\n",
      "    retweets, tweet = regex_clean(re_retweets, tweet)\n",
      "    retweets_count.update(retweets)  \n",
      "    urls, tweet = regex_clean(re_urls, tweet)\n",
      "    mentions, tweet = regex_clean(re_mentions, tweet)\n",
      "    words = [word.lower() for word in wordpunct_tokenize(tweet) if word.lower() not in global_stop and not word.isdigit()]\n",
      "    words = [word for word in words if word not in punctuation]\n",
      "    if notShout(words):\n",
      "        acronyms = [a for a in re.findall(re_acronym, tweet) if a.lower() not in global_stop]\n",
      "        acronyms_count.update(acronyms)\n",
      "        cap_words = re.findall(re_comp, tweet)\n",
      "        cap_words_count.update(cap_words)\n",
      "        #debug\n",
      "#         print '|urls %s' %urls\n",
      "#         print '|hashtags %s' %hashtags\n",
      "#         print '|mentions %s' %mentions\n",
      "#         print '|retweets %s' %retweets\n",
      "#         print '|cap_words %s' %cap_words\n",
      "#         print '|acronyms %s' %acronyms\n",
      "#         print words\n",
      "        if len(retweets)==0:\n",
      "             #counts and sets - maybe do something with the url set\n",
      "            word_count.update(words)\n",
      "            hashtag_count.update(hashtags) \n",
      "            url_set |= set(urls)\n",
      "            mentions_count.update(mentions)\n",
      "            user_hashtag_edges = [(screen_name,h) for h in hashtags]\n",
      "            user_hashtag.add_edges_from(user_hashtag_edges)\n",
      "            if screen_name in user_word_dict.keys():\n",
      "                user_word_dict[screen_name]+=words\n",
      "            else:\n",
      "                user_word_dict[screen_name]=words\n",
      "            for c1, c2 in list(combinations(words, 2)):\n",
      "                graph_add_edge(c1, c2, wordco)\n",
      "            \n",
      "#             word_set |= set(words)  \n",
      "    #     mention_set |= set(mentions)\n",
      "    #     retweets_set |= set(retweets)\n",
      "        else:\n",
      "            tweets_retweeted += 1\n",
      "    else:\n",
      "        shout_count += 1\n",
      "    # print \"----------------\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'tweets retweeted: %d' %tweets_retweeted\n",
      "print 'retweeted users: %d' %len(retweets_count)\n",
      "print 'mentioned users: %d' %len(mentions_count)\n",
      "print 'shouts: %d' %shout_count\n",
      "print 'tweets analyzed: %d' %(len(top_tweeter_tweets)-tweets_retweeted-shout_count)\n",
      "print 'number of unique words: %d' %len(word_count.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "tweets retweeted: 16204\n",
        "retweeted users: 3620\n",
        "mentioned users: 6058\n",
        "shouts: 553\n",
        "tweets analyzed: 2711\n",
        "number of unique words: 15128\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#bipartite\n",
      "for sn,words in user_word_dict.items():\n",
      "    words_to_add = [word for word in words if word_count[word]>1]\n",
      "    for to_add in words_to_add:\n",
      "        graph_add_node(sn, user_words, {'bipartite':0})\n",
      "        graph_add_node(to_add, user_words, {'bipartite':1})\n",
      "        graph_add_edge(sn, to_add, user_words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#tripartite\n",
      "filter_hashtags = ['commoncore', 'CommonCore', 'CCSS', 'ccss', 'Commoncore']\n",
      "hashtag_user_words = nx.Graph()\n",
      "for sn,words in user_word_dict.items():\n",
      "    words_to_add = [word for word in words if word_count[word]>1]\n",
      "    for to_add in words_to_add:\n",
      "        graph_add_node(sn, hashtag_user_words, {'tripartite':0})\n",
      "        graph_add_node(to_add, hashtag_user_words, {'tripartite':1})\n",
      "        hashtags = list(hashtagdf[hashtagdf.screen_name==sn].hashtag) \n",
      "        hashtags = [h.lower() for h in hashtags if h not in filter_hashtags]\n",
      "        graph_add_edge(sn, to_add, hashtag_user_words)\n",
      "        for h in hashtags:\n",
      "            graph_add_node(h, hashtag_user_words, {'tripartite':2})\n",
      "            graph_add_edge(sn, h, hashtag_user_words)  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nx.write_gexf(user_words, '%s_tweet_graph.gexf' %'all_user_words')\n",
      "print '%s_tweet_graph.gexf' %'all_user_words'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "all_user_words_tweet_graph.gexf\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " \n",
      "    "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"number of nodes %d\" %user_words.number_of_nodes()\n",
      "print \"number of edges %d\" %user_words.number_of_edges()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "number of nodes 20529\n",
        "number of edges 119504\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"number of nodes %d\" %wordco.number_of_nodes()\n",
      "print \"number of edges %d\" %wordco.number_of_edges()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "number of nodes 15086\n",
        "number of edges 282566"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "nx.write_gexf(wordco, '%s_tweet_graph.gexf' %'all_wordco')\n",
      "print '%s_tweet_graph.gexf' %'all_wordco'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "UnicodeDecodeError",
       "evalue": "'unicodeescape' codec can't decode byte 0x5c in position 1: \\ at end of string",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-55-a7f61cf784d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_gexf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordco\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%s_tweet_graph.gexf'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m'all_wordco'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'%s_tweet_graph.gexf'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m'all_wordco'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Aankit/Documents/SocialDataAnalysis/commonCore/lib/python2.7/site-packages/networkx/readwrite/gexf.pyc\u001b[0m in \u001b[0;36mwrite_gexf\u001b[0;34m(G, path, encoding, prettyprint, version)\u001b[0m\n",
        "\u001b[0;32m/Users/Aankit/Documents/SocialDataAnalysis/commonCore/lib/python2.7/site-packages/networkx/utils/decorators.pyc\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Finally, we call the original function, making sure to close the fobj.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclose_fobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Aankit/Documents/SocialDataAnalysis/commonCore/lib/python2.7/site-packages/networkx/readwrite/gexf.pyc\u001b[0m in \u001b[0;36mwrite_gexf\u001b[0;34m(G, path, encoding, prettyprint, version)\u001b[0m\n\u001b[1;32m     75\u001b[0m     writer = GEXFWriter(encoding=encoding,prettyprint=prettyprint,\n\u001b[1;32m     76\u001b[0m                         version=version)\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Aankit/Documents/SocialDataAnalysis/commonCore/lib/python2.7/site-packages/networkx/readwrite/gexf.pyc\u001b[0m in \u001b[0;36madd_graph\u001b[0;34m(self, G)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mgraph_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"graph\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdefaultedgetype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_element\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Aankit/Documents/SocialDataAnalysis/commonCore/lib/python2.7/site-packages/networkx/readwrite/gexf.pyc\u001b[0m in \u001b[0;36madd_nodes\u001b[0;34m(self, G, graph_element)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mnode_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m             \u001b[0mnode_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0mkw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Aankit/Documents/SocialDataAnalysis/commonCore/lib/python2.7/site-packages/networkx/utils/misc.pyc\u001b[0m in \u001b[0;36mmake_str\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;31m# unicode(3) works, but unicode(3, 'unicode-escape') wants a buffer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'unicode-escape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'unicodeescape' codec can't decode byte 0x5c in position 1: \\ at end of string"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'number of nodes %d' %user_hashtag.number_of_nodes()\n",
      "print 'number of edges %d' %user_hashtag.number_of_edges()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "number of nodes 8732\n",
        "number of edges 11998"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nx.write_gexf(user_hashtag, '%s_tweet_graph.gexf' %'all_user_hashtag')\n",
      "print '%s_tweet_graph.gexf' %'all_user_hashtag'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "all_user_hashtag_tweet_graph.gexf\n"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'number of nodes %d' %hashtag_user_words.number_of_nodes()\n",
      "print 'number of edges %d' %hashtag_user_words.number_of_edges()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "number of nodes 23940\n",
        "number of edges 134090\n"
       ]
      }
     ],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nx.write_gexf(hashtag_user_words, '%s_tweet_graph.gexf' %'hashtag_user_words')\n",
      "print '%s_tweet_graph.gexf' %'hashtag_user_words'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hashtag_user_words_tweet_graph.gexf\n"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "mentions_count.most_common(50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 89,
       "text": [
        "[('arneduncan', 633),\n",
        " ('wordpressdotcom', 242),\n",
        " ('educationweek', 197),\n",
        " ('po_st', 170),\n",
        " ('YouTube', 159),\n",
        " ('JebBush', 143),\n",
        " ('FoxNews', 104),\n",
        " ('DailySignal', 103),\n",
        " ('sharethis', 90),\n",
        " ('DianeRavitch', 83),\n",
        " ('nprnews', 83),\n",
        " ('scoopit', 81),\n",
        " ('TruthinAmEd', 71),\n",
        " ('BreitbartNews', 71),\n",
        " ('MichaelPetrilli', 68),\n",
        " ('HuffPostEdu', 68),\n",
        " ('theblaze', 63),\n",
        " ('theEagleiRising', 61),\n",
        " ('lindseymburke', 60),\n",
        " ('kelseyjharkness', 58),\n",
        " ('GOP', 55),\n",
        " ('michellemalkin', 54),\n",
        " ('MadWorldNews', 51),\n",
        " ('jstines3', 50),\n",
        " ('edutopia', 47),\n",
        " ('techsavvyed', 47),\n",
        " ('LadyLiberty1885', 46),\n",
        " ('NatUrbanLeague', 46),\n",
        " ('JohnKingNYSED', 42),\n",
        " ('EngageNY', 41),\n",
        " ('LearningFirst', 41),\n",
        " ('washingtonpost', 39),\n",
        " ('BadassTeachersA', 39),\n",
        " ('Heritage', 38),\n",
        " ('TwitchyTeam', 34),\n",
        " ('DCClothesline', 34),\n",
        " ('isteconnects', 34),\n",
        " ('rweingarten', 32),\n",
        " ('rickhess99', 32),\n",
        " ('JohnKasich', 31),\n",
        " ('NealMcCluskey', 31),\n",
        " ('_DianeDouglas', 30),\n",
        " ('BobbyJindal', 29),\n",
        " ('cummins_lisa', 29),\n",
        " ('jjauthor', 29),\n",
        " ('RobAstorino', 29),\n",
        " ('WSJ', 28),\n",
        " ('All4Eds', 28),\n",
        " ('carolburris', 28),\n",
        " ('Phoenix2a1', 27)]"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "retweets_count.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 90,
       "text": [
        "[('AboutCommonCore', 546),\n",
        " ('educationweek', 500),\n",
        " ('FreedomWorks', 200),\n",
        " ('michellemalkin', 184),\n",
        " ('BreitbartNews', 152),\n",
        " ('jstines3', 134),\n",
        " ('CommonCores', 124),\n",
        " ('Heritage', 117),\n",
        " ('DianeRavitch', 114),\n",
        " ('Rob_Cunningham', 113)]"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "hashtag_count.most_common(50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "[(u'commoncore', 6441),\n",
        " ('CommonCore', 3449),\n",
        " (u'ccss', 1985),\n",
        " (u'tcot', 1334),\n",
        " (u'stopcommoncore', 1190),\n",
        " (u'education', 982),\n",
        " ('CCSS', 952),\n",
        " (u'edchat', 930),\n",
        " (u'pjnet', 692),\n",
        " ('StopCommonCore', 476),\n",
        " (u'edtech', 461),\n",
        " (u'math', 415),\n",
        " ('PJNET', 332),\n",
        " (u'ccot', 319),\n",
        " ('USA', 280),\n",
        " (u'teaparty', 229),\n",
        " (u'usa', 204),\n",
        " (u'mathchat', 195),\n",
        " ('CCOT', 194),\n",
        " ('RT', 193),\n",
        " ('TCOT', 172),\n",
        " (u'ipad', 172),\n",
        " (u'homework', 168),\n",
        " ('Education', 166),\n",
        " (u'edreform', 164),\n",
        " (u'common', 163),\n",
        " ('TeaParty', 150),\n",
        " (u'news', 145),\n",
        " (u'teaching', 144),\n",
        " ('Common', 143),\n",
        " (u'tlot', 142),\n",
        " (u'engchat', 130),\n",
        " (u'iphone', 123),\n",
        " (u'app', 123),\n",
        " (u'ccsstech', 122),\n",
        " (u'sisterpatriots', 122),\n",
        " (u'election2014', 116),\n",
        " ('039', 116),\n",
        " (u'parents', 113),\n",
        " (u'parcc', 109),\n",
        " (u'android', 107),\n",
        " (u'teachers', 106),\n",
        " (u'eie14', 105),\n",
        " (u'obamacare', 100),\n",
        " ('MakeDCListen', 100),\n",
        " (u'money', 99),\n",
        " (u'gop', 99),\n",
        " (u'schoolchoice', 92),\n",
        " ('Conservatives', 89),\n",
        " (u'forex', 85)]"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "h = list(hashtagdf[hashtagdf.screen_name=='Commoncorediva'].hashtag)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "type(h)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 82,
       "text": [
        "list"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 83,
       "text": [
        "[u'StopCommonCore', u'stopcommoncore', u'thflehrman']"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_count.most_common(50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 100,
       "text": [
        "[('math', 1991),\n",
        " ('teachers', 1357),\n",
        " ('stop', 1327),\n",
        " ('parents', 1246),\n",
        " ('education', 1210),\n",
        " ('bush', 1167),\n",
        " ('tests', 1087),\n",
        " ('jeb', 987),\n",
        " ('new', 963),\n",
        " ('testing', 920),\n",
        " ('admits', 919),\n",
        " ('state', 882),\n",
        " ('school', 825),\n",
        " ('repeal', 773),\n",
        " ('kids', 713),\n",
        " ('grade', 706),\n",
        " ('students', 688),\n",
        " ('curriculum', 676),\n",
        " ('arts', 669),\n",
        " ('schools', 668),\n",
        " ('add', 666),\n",
        " ('bill', 654),\n",
        " ('lets', 640),\n",
        " ('give', 632),\n",
        " ('illegalendorsement', 611),\n",
        " ('poll', 597),\n",
        " ('reading', 566),\n",
        " ('low', 560),\n",
        " ('marks', 547),\n",
        " ('reasonable', 527),\n",
        " ('need', 498),\n",
        " ('support', 496),\n",
        " ('help', 480),\n",
        " ('high', 458),\n",
        " ('take', 455),\n",
        " ('end', 449),\n",
        " ('ohio', 445),\n",
        " ('video', 438),\n",
        " ('get', 437),\n",
        " ('children', 428),\n",
        " ('teacher', 423),\n",
        " ('like', 412),\n",
        " ('parent', 402),\n",
        " ('test', 401),\n",
        " ('failing', 399),\n",
        " ('la', 391),\n",
        " ('states', 385),\n",
        " ('know', 366),\n",
        " ('seeks', 349),\n",
        " ('one', 347)]"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}